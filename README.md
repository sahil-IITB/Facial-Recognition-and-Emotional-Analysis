This repository documents our journey into Machine Learning using Python and PyTorch. We began with foundational concepts and progressively built hands-on experience with real-world datasets and model development.

What We’ve Learned So Far :
Python Libraries for Data Science
We started by familiarizing ourselves with essential Python libraries commonly used in data science and machine learning:
1.NumPy – for efficient numerical operations and array manipulation.
2.Pandas – for data manipulation and analysis using DataFrames.
3.Matplotlib – for data visualization and plotting.

Introduction to PyTorch
We transitioned into using PyTorch, one of the most popular deep learning frameworks. Key concepts covered include:
1.Understanding Tensors and their operations.
2.Creating custom neural networks using torch.nn.
3.Using optimizers, loss functions, and managing device (CPU/GPU) allocations.

Dataset Handling with torchvision
We learned how to:
1.Import and preprocess datasets using torchvision.datasets and torchvision.transforms.
2.Load data efficiently using DataLoader with batching and shuffling mechanisms.

Supervised Learning Models
We implemented and trained various supervised learning models, with a focus on classification tasks. We explored:
1.Building feedforward neural networks.
2.Applying activation functions like ReLU and Softmax.
3.Monitoring accuracy and loss during training.

MNIST Digit Classification (Assignment)
As a hands-on assignment, we developed a deep learning model to classify handwritten digits using the MNIST dataset. In this process, we:
1.Prepared the data and normalized input images.
2.Built a neural network architecture from scratch.
3.Trained the model using Stochastic Gradient Descent (SGD).
4.Observed how weights are updated during backpropagation.
5.Understood the mechanics of gradient descent and the role of learning rates.
6.Evaluated model performance and discussed ways to improve accuracy.
